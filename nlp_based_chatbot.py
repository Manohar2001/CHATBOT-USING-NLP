# -*- coding: utf-8 -*-
"""NLP-Based ChatBot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UGC83-16UQ5PvFv2sr1SAi-s6FBksG2r

Importing all the necessary libraries
"""

import random
import string  #punctuation, data preprocessing
import numpy as np
import io
from sklearn.feature_extraction.text import TfidfVectorizer  #data encoding
from sklearn.metrics.pairwise import cosine_similarity  #similarity based response generation
import warnings
warnings.filterwarnings('ignore')
import nltk
from nltk.stem import WordNetLemmatizer  #data preprocessing
nltk.download('punkt')
nltk.download('wordnet')

pip install wikipedia

"""Function for tokenization"""

def tokenize(user_query):
  #file = open('corpus.txt', 'r', errors='ignore')
  corpus = wikipedia.summary(user_query, sentences = 10)
  #corpus = file.read()
  sentence_tokens = nltk.sent_tokenize(corpus)
  word_tokens = nltk.word_tokenize(corpus)

  return sentence_tokens, word_tokens

"""Function for lemmatization"""

lemmatizer = WordNetLemmatizer()

def lemtokens(tokens):
  list = []
  for i in tokens:
    list.append(lemmatizer.lemmatize(i))
  return list

#to remove punctuation:
punct = dict((ord(i), None) for i in string.punctuation)

def lemmer(text):
  tokenized_text = nltk.word_tokenize(text.lower().translate(punct))
  return lemtokens(tokenized_text)  #lemmatized values

greeting_inputs = ['hello','hi','hey','greetings']
greeting_responses = ['I am a chatbot','hello','hi','whats up','hi there']

def greeting(text):
    #Tokenize
    for token in text.split():
        #inputs
        if token.lower() in greeting_inputs:
            return random.choice(greeting_responses)

"""Generate Response

Data Encoding - TFIDF
Similarity metric - Cosine similarity choosing the vector with maximum similarity in the corpus
"""

def respond(user_query):
  bot_response = ''

  sent_tokens, word_tokens = tokenize(user_query)
  sent_tokens.append(user_query)

  tfidf_obj = TfidfVectorizer(tokenizer = lemmer, stop_words = 'english')
  tfidf = tfidf_obj.fit_transform(sent_tokens)

  #cosine similarity
  sim_values = cosine_similarity(tfidf[-1], tfidf)

  index = sim_values.argsort()[0][-2]

  flattened_sim = sim_values.flatten()

  flattened_sim.sort()

  required_tfidf = flattened_sim[-2]

  if(required_tfidf == 0):
    bot_response += 'I cannot understand'
    return bot_response
  else:
    bot_response += bot_response + sent_tokens[index]
    return bot_response

"""Main Function:"""

import wikipedia

#wikipedia.summary('orange fruit')

print("ChatBot")
flag = 1

while(flag == 1):
  user_query = input()
  user_query = user_query.lower()

  if(user_query == 'exit'):
    flag = 0
    print("Bot: Bye, please let me know whenever i am necessary!")
  else:
    if(greeting(user_query) != None):
          print("Bot: "+greeting(user_query))

    else:
          res = respond(user_query)
          print("Bot: ",res)